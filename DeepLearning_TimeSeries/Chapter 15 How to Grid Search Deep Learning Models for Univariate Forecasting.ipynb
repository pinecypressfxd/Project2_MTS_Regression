{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59d9c97",
   "metadata": {},
   "source": [
    "# Chapter 15 How to Grid Search Deep Learning Models for Univariate Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdfea8c",
   "metadata": {},
   "source": [
    "In this tutorial, you will discover how to develop a framework to grid search hyperparameters for deep learning models. After completing this tutorial, you will know:\n",
    "- How to develop a generic grid searching framework for tuning model hyperparameters.\n",
    "- How to grid search hyperparameters for a Multilayer Perceptron model on the airline\n",
    "passengers univariate time series forecasting problem.\n",
    "- How to adapt the framework to grid search hyperparameters for convolutional and long short-term memory neural networks.\n",
    "Let’s get started.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ff8e2",
   "metadata": {},
   "source": [
    "## 15.1 Tutorial Overview\n",
    "This tutorial is divided into five parts; they are:\n",
    "1. Time Series Problem\n",
    "2. Grid Search Framework\n",
    "3. Multilayer Perceptron Model\n",
    "4. Convolutional Neural Network Model\n",
    "5. Long Short-Term Memory Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257a5091",
   "metadata": {},
   "source": [
    "## 15.2 Time Series Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0105d5a0",
   "metadata": {},
   "source": [
    "In this tutorial we will focus on one dataset and use it as the context to demonstrate the development of a grid searching framework for range of deep learning models for univariate time series forecasting. \n",
    "\n",
    "We will use the monthly airline passenger dataset as this context as it includes the complexity of both trend and seasonal elements. The monthly airline passenger dataset summarizes the monthly total number of international passengers in thousands on for an airline from 1949 to 1960."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "347f0d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load and plot monthly airline passengers dataset\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "# load\n",
    "series = read_csv('monthly-airline-passengers.csv', header=0, index_col=0) # summarize shape\n",
    "print(series.shape)\n",
    "# plot\n",
    "pyplot.plot(series)\n",
    "pyplot.xticks([])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9685ba04",
   "metadata": {},
   "source": [
    "## 15.3 Develop a Grid Search Framework\n",
    "In this section, we will develop a grid search test harness that can be used to evaluate a range of hyperparameters for different neural network models, such as MLPs, CNNs, and LSTMs. This section is divided into the following parts:\n",
    "1. Train-Test Split\n",
    "2. Series as Supervised Learning \n",
    "3. Walk-Forward Validation\n",
    "4. Repeat Evaluation\n",
    "5. Summarize Performance\n",
    "6. Worked Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eead4cd",
   "metadata": {},
   "source": [
    "### 15.3.1 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53665d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35060bc9",
   "metadata": {},
   "source": [
    "### 15.3.2 Series as Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fc9bd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "a = np.arange(1,10,1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3ebfb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in, n_out=1):\n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c5f9f9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3., 4., 5., 6.],\n",
       "       [2., 3., 4., 5., 6., 7.],\n",
       "       [3., 4., 5., 6., 7., 8.],\n",
       "       [4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 前4列为输入数据，后两列为输出数据\n",
    "series_to_supervised(a,4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8a889bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference dataset\n",
    "def difference(data, order):\n",
    "    return [data[i] - data[i - order] for i in range(order, len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f97f0867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1.])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference(series_to_supervised(a,4,2),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bb3eeb",
   "metadata": {},
   "source": [
    "### 15.3.3 Walk-Forward Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b55bee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b72312d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3a9de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1708e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # fit model\n",
    "    model = model_fit(train, cfg)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = model_predict(model, history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions) \n",
    "    print(' > %.3f' % error)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046a124",
   "metadata": {},
   "source": [
    "### 15.3.4 Repeat Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36b3d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score a model, return None on failure\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=10):\n",
    "    # convert config to a key\n",
    "    key = str(config)\n",
    "    # fit and evaluate the model n times\n",
    "    scores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)] # summarize score\n",
    "    result = mean(scores)\n",
    "    print('> Model[%s] %.3f' % (key, result))\n",
    "    return (key, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a5283",
   "metadata": {},
   "source": [
    "### 15.3.5 Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fe51f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test):\n",
    "    # evaluate configs\n",
    "    scores = scores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "    # sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ec3c4b",
   "metadata": {},
   "source": [
    "### 15.3.6 Worked Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb0ff7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 27.000\n",
      " > 27.000\n",
      " > 27.000\n",
      " > 27.000\n",
      " > 27.000\n",
      " > 27.000\n",
      " > 27.000\n",
      " > 27.000\n",
      " > 27.000\n",
      " > 27.000\n",
      "> Model[12] 27.000\n",
      " > 48.544\n",
      " > 48.544\n",
      " > 48.544\n",
      " > 48.544\n",
      " > 48.544\n",
      " > 48.544\n",
      " > 48.544\n",
      " > 48.544\n",
      " > 48.544\n",
      " > 48.544\n",
      "> Model[12] 48.544\n",
      " > 50.708\n",
      " > 50.708\n",
      " > 50.708\n",
      " > 50.708\n",
      " > 50.708\n",
      " > 50.708\n",
      " > 50.708\n",
      " > 50.708\n",
      " > 50.708\n",
      " > 50.708\n",
      "> Model[12] 50.708\n",
      " > 49.987\n",
      " > 49.987\n",
      " > 49.987\n",
      " > 49.987\n",
      " > 49.987\n",
      " > 49.987\n",
      " > 49.987\n",
      " > 49.987\n",
      " > 49.987\n",
      " > 49.987\n",
      "> Model[12] 49.987\n",
      " > 41.979\n",
      " > 41.979\n",
      " > 41.979\n",
      " > 41.979\n",
      " > 41.979\n",
      " > 41.979\n",
      " > 41.979\n",
      " > 41.979\n",
      " > 41.979\n",
      " > 41.979\n",
      "> Model[12] 41.979\n",
      "done\n",
      "12 27.0\n",
      "12 41.97916149710473\n",
      "12 48.54379466007988\n",
      "12 49.986664888414666\n",
      "12 50.708316214732804\n"
     ]
    }
   ],
   "source": [
    "# grid search persistence models for monthly airline passengers dataset\n",
    "from math import sqrt\n",
    "from numpy import mean\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    return None\n",
    "\n",
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, offset):\n",
    "    return history[-offset]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # fit model\n",
    "    model = model_fit(train, cfg)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = model_predict(model, history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions) \n",
    "    print(' > %.3f' % error)\n",
    "    return error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=10):\n",
    "    # convert config to a key\n",
    "    key = str(config)\n",
    "    # fit and evaluate the model n times\n",
    "    scores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)] # summarize score\n",
    "    result = mean(scores)\n",
    "    print('> Model[%s] %.3f' % (key, result))\n",
    "    return (key, result)\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test):\n",
    "    # evaluate configs\n",
    "    scores  = [repeat_evaluate(data, n_test, cfg) for cfg in cfg_list]\n",
    "    # sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # define dataset\n",
    "    series = read_csv('monthly-airline-passengers.csv', header=0, index_col=0) \n",
    "    data = series.values\n",
    "    # data split\n",
    "    n_test = 12\n",
    "    # model configs\n",
    "    cfg_list = [1, 6, 12, 24, 36]\n",
    "    # grid search\n",
    "    scores = grid_search(data, cfg_list, n_test) \n",
    "    print('done')\n",
    "    # list top 10 configs\n",
    "    for cfg, error in scores[:10]:\n",
    "        print(cfg, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabbf838",
   "metadata": {},
   "source": [
    "## 15.4 Multilayer Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c488ddb",
   "metadata": {},
   "source": [
    "There are many aspects of the MLP that we may wish to tune. We will define a very simple model with one hidden layer and define five hyperparameters to tune. They are:\n",
    "- n input: The number of prior inputs to use as input for the model (e.g. 12 months). \n",
    "- n nodes: The number of nodes to use in the hidden layer (e.g. 50).\n",
    "- n epochs: The number of training epochs (e.g. 1000).\n",
    "- n batch: The number of samples to include in each minibatch (e.g. 32).\n",
    "- n diff: The difference order (e.g. 0 or 12)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02700e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by no means == not at all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e5f72",
   "metadata": {},
   "source": [
    "一旦模型拟合，我们就可以用它来进行预测。如果数据存在差分，则必须反转差分才能预测模型。这涉及将历史相对偏移处的值添加回模型预测的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de11c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert difference\n",
    "correction = 0.0\n",
    "if n_diff > 0:\n",
    "    correction = history[-n_diff]\n",
    "...\n",
    "# correct forecast if it was differenced\n",
    "return correction + yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0f91ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    # unpack config\n",
    "    n_input, n_nodes, n_epochs, n_batch, n_diff = config\n",
    "    # prepare data\n",
    "    if n_diff > 0:\n",
    "        train = difference(train, n_diff)\n",
    "    # transform series into supervised format\n",
    "    data = series_to_supervised(train, n_input)\n",
    "    # separate inputs and outputs\n",
    "    train_x, train_y = data[:, :-1], data[:, -1]\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_nodes, activation='relu', input_dim=n_input)) \n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit model\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7e11b9",
   "metadata": {},
   "source": [
    "**The complete example is listed below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4602c499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configs: 8\n",
      " > 479.897\n",
      " > 480.664\n",
      " > 479.939\n",
      " > 480.827\n",
      " > 479.643\n",
      " > 481.203\n",
      " > 480.250\n",
      " > 480.988\n",
      " > 479.461\n",
      " > 481.192\n",
      "> Model[[12, 50, 100, 1, 0]] 480.406\n",
      " > 20.470\n",
      " > 19.559\n",
      " > 19.659\n",
      " > 20.019\n",
      " > 20.702\n",
      " > 22.057\n",
      " > 24.034\n",
      " > 19.239\n",
      " > 21.567\n",
      " > 21.152\n",
      "> Model[[12, 50, 100, 1, 12]] 20.846\n",
      " > 481.872\n",
      " > 481.858\n",
      " > 481.877\n",
      " > 481.838\n",
      " > 481.864\n",
      " > 481.855\n",
      " > 481.886\n",
      " > 481.902\n",
      " > 481.897\n",
      " > 481.883\n",
      "> Model[[12, 50, 100, 150, 0]] 481.873\n",
      " > 19.088\n",
      " > 19.660\n",
      " > 18.486\n",
      " > 21.087\n",
      " > 18.418\n",
      " > 18.423\n",
      " > 21.553\n",
      " > 20.367\n",
      " > 20.878\n",
      " > 19.587\n",
      "> Model[[12, 50, 100, 150, 12]] 19.755\n",
      " > 480.330\n",
      " > 480.406\n",
      " > 481.043\n",
      " > 480.831\n",
      " > 479.957\n",
      " > 480.657\n",
      " > 479.984\n",
      " > 480.707\n",
      " > 480.915\n",
      " > 481.008\n",
      "> Model[[12, 100, 100, 1, 0]] 480.584\n",
      " > 16.758\n",
      " > 19.102\n",
      " > 19.817\n",
      " > 17.657\n",
      " > 18.887\n",
      " > 18.423\n",
      " > 20.173\n",
      " > 21.128\n",
      " > 19.668\n",
      " > 19.272\n",
      "> Model[[12, 100, 100, 1, 12]] 19.089\n",
      " > 481.844\n",
      " > 481.878\n",
      " > 481.903\n",
      " > 481.899\n",
      " > 481.881\n",
      " > 481.890\n",
      " > 481.888\n",
      " > 481.893\n",
      " > 481.871\n",
      " > 481.866\n",
      "> Model[[12, 100, 100, 150, 0]] 481.881\n",
      " > 18.905\n",
      " > 19.235\n",
      " > 18.762\n",
      " > 19.324\n",
      " > 19.536\n",
      " > 19.181\n",
      " > 18.108\n",
      " > 19.844\n",
      " > 18.589\n",
      " > 19.399\n",
      "> Model[[12, 100, 100, 150, 12]] 19.088\n",
      "done\n",
      "[12, 100, 100, 150, 12] 19.088099215015696\n",
      "[12, 100, 100, 1, 12] 19.088538388703387\n",
      "[12, 50, 100, 150, 12] 19.75467902028306\n"
     ]
    }
   ],
   "source": [
    "# grid search mlps for monthly airline passengers dataset\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in, n_out=1):\n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg.values\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# difference dataset\n",
    "def difference(data, order):\n",
    "    return [data[i] - data[i - order] for i in range(order, len(data))]\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    # unpack config\n",
    "    n_input, n_nodes, n_epochs, n_batch, n_diff = config\n",
    "    # prepare data\n",
    "    if n_diff > 0:\n",
    "        train = difference(train, n_diff)\n",
    "    # transform series into supervised format\n",
    "    data = series_to_supervised(train, n_input)\n",
    "    # separate inputs and outputs\n",
    "    train_x, train_y = data[:, :-1], data[:, -1]\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_nodes, activation='relu', input_dim=n_input))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit model\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "    return model\n",
    "\n",
    "# forecast with the fit model\n",
    "def model_predict(model, history, config):\n",
    "    # unpack config\n",
    "    n_input, _, _, _, n_diff = config\n",
    "    # prepare data\n",
    "    correction = 0.0\n",
    "    if n_diff > 0:\n",
    "        correction = history[-n_diff]\n",
    "    history = difference(history, n_diff)\n",
    "    # shape input for model\n",
    "    x_input = array(history[-n_input:]).reshape((1, n_input))\n",
    "    # make forecast\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    # correct forecast if it was differenced\n",
    "    return correction + yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # fit model\n",
    "    model = model_fit(train, cfg)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = model_predict(model, history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions) \n",
    "    print(' > %.3f' % error)\n",
    "    return error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=10):\n",
    "    # convert config to a key\n",
    "    key = str(config)\n",
    "    # fit and evaluate the model n times\n",
    "    scores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)] # summarize score\n",
    "    result = mean(scores)\n",
    "    print('> Model[%s] %.3f' % (key, result))\n",
    "    return (key, result)\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test):\n",
    "    # evaluate configs\n",
    "    scores  = [repeat_evaluate(data, cfg, n_test) for cfg in cfg_list]\n",
    "    # sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores\n",
    "\n",
    "# create a list of configs to try\n",
    "def model_configs():\n",
    "    # define scope of configs\n",
    "    n_input = [12]\n",
    "    n_nodes = [50, 100]\n",
    "    n_epochs = [100]\n",
    "    n_batch = [1, 150]\n",
    "    n_diff = [0, 12]\n",
    "    # create configs\n",
    "    configs = list()\n",
    "    for i in n_input:\n",
    "        for j in n_nodes:\n",
    "            for k in n_epochs:\n",
    "                for l in n_batch:\n",
    "                    for m in n_diff:\n",
    "                        cfg = [i, j, k, l, m]\n",
    "                        configs.append(cfg)\n",
    "    print('Total configs: %d' % len(configs)) \n",
    "    return configs\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # define dataset\n",
    "    series = read_csv('monthly-airline-passengers.csv', header=0, index_col=0) \n",
    "    data = series.values\n",
    "    # data split\n",
    "    n_test = 12\n",
    "    # model configs\n",
    "    cfg_list = model_configs()\n",
    "    # grid search\n",
    "#     print(data,cfg_list,n_test)\n",
    "    scores = grid_search(data, cfg_list, n_test) \n",
    "    print('done')\n",
    "    # list top 3 configs\n",
    "    for cfg, error in scores[:3]:\n",
    "        print(cfg, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa18c2f9",
   "metadata": {},
   "source": [
    "The scores are then sorted and the top 3 configurations with the lowest RMSE are reported at the end. A skillful model configuration was found as compared to a naive model that reported an RMSE of 50.70. We can see that the best RMSE of 18.98 was achieved with a configuration of [12, 100, 100, 1, 12], which we know can be interpreted as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8f4b2f",
   "metadata": {},
   "source": [
    "- n input: 12\n",
    "- n nodes: 100 \n",
    "- n epochs: 100\n",
    "- n batch: 1\n",
    "- n diff: 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde92d11",
   "metadata": {},
   "source": [
    "## 15.5 Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586dfb91",
   "metadata": {},
   "source": [
    "We can now adapt the framework to grid search CNN models. For more details on modeling a univariate time series with a CNN, see Chapter 8. Much the same set of hyperparameters can be searched as with the MLP model, except the number of nodes in the hidden layer can be replaced by the number of filter maps and kernel size in the convolutional layers. The chosen set of hyperparameters to grid search in the CNN model are as follows:\n",
    "\n",
    "- n input: The number of prior inputs to use as input for the model (e.g. 12 months). \n",
    "- n filters: The number of filter maps in the convolutional layer (e.g. 32).\n",
    "- n kernel: The kernel size in the convolutional layer (e.g. 3).\n",
    "- n epochs: The number of training epochs (e.g. 1000).\n",
    "- n batch: The number of samples to include in each minibatch (e.g. 32). \n",
    "- n diff: The difference order (e.g. 0 or 12).\n",
    "\n",
    "- n 输入：用作模型输入的先前输入数（例如 12 个月）。\n",
    "- n 个过滤器：卷积层中过滤器映射的数量（例如 32 个）。\n",
    "- n 内核：卷积层中的内核大小（例如 3）。\n",
    "- n 个时期：训练时期的数量（例如 1000）。\n",
    "- n 批次：每个小批次中包含的样品数量（例如 32）。\n",
    "- n diff：差分阶次（例如 0 或 12）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39151f23",
   "metadata": {},
   "source": [
    "Making a prediction with a fit CNN model is very much like making a prediction with a fit MLP. Again, the only difference is that the one sample worth of input data must have a **three-dimensional** shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3562d63",
   "metadata": {},
   "source": [
    "- **The complete example is listed below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b5d6b798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configs: 8\n",
      " > 478.733\n",
      " > 479.524\n",
      " > 479.285\n",
      "> Model[[12, 64, 3, 100, 1, 0]] 479.181\n",
      " > 19.728\n",
      " > 20.200\n",
      " > 22.325\n",
      "> Model[[12, 64, 3, 100, 1, 12]] 20.751\n",
      " > 481.765\n",
      " > 481.784\n",
      " > 481.789\n",
      "> Model[[12, 64, 3, 100, 150, 0]] 481.780\n",
      " > 18.663\n",
      " > 19.199\n",
      " > 18.186\n",
      "> Model[[12, 64, 3, 100, 150, 12]] 18.682\n",
      " > 479.498\n",
      " > 479.405\n",
      " > 479.492\n",
      "> Model[[12, 64, 5, 100, 1, 0]] 479.465\n",
      " > 19.848\n",
      " > 17.793\n",
      " > 18.375\n",
      "> Model[[12, 64, 5, 100, 1, 12]] 18.672\n",
      " > 481.791\n",
      " > 481.792\n",
      " > 481.815\n",
      "> Model[[12, 64, 5, 100, 150, 0]] 481.800\n",
      " > 19.856\n",
      " > 20.045\n",
      " > 18.730\n",
      "> Model[[12, 64, 5, 100, 150, 12]] 19.544\n",
      "done\n",
      "[12, 64, 5, 100, 1, 12] 18.671719329801594\n",
      "[12, 64, 3, 100, 150, 12] 18.682417615212\n",
      "[12, 64, 5, 100, 150, 12] 19.543837626617503\n"
     ]
    }
   ],
   "source": [
    "# grid search cnn for monthly airline passengers dataset\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in, n_out=1):\n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg.values\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# difference dataset\n",
    "def difference(data, order):\n",
    "    return [data[i] - data[i - order] for i in range(order, len(data))]\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    # unpack config\n",
    "    n_input, n_filters, n_kernel, n_epochs, n_batch, n_diff = config\n",
    "    # prepare data\n",
    "    if n_diff > 0:\n",
    "        train = difference(train, n_diff)\n",
    "    # transform series into supervised format\n",
    "    data = series_to_supervised(train, n_in=n_input)\n",
    "    # separate inputs and outputs\n",
    "    train_x, train_y = data[:, :-1], data[:, -1]\n",
    "    \n",
    "    # reshape input data into [samples, timesteps, features]\n",
    "    n_features = 1\n",
    "    train_x = train_x.reshape((train_x.shape[0], train_x.shape[1], n_features))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(n_filters, n_kernel, activation='relu', input_shape=(n_input,\n",
    "    n_features)))\n",
    "    model.add(MaxPooling1D()) \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1)) \n",
    "    model.compile(loss='mse', optimizer='adam') # fit\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "    return model\n",
    "\n",
    "# forecast with the fit model\n",
    "def model_predict(model, history, config):\n",
    "    # unpack config\n",
    "    n_input, _, _, _, _, n_diff = config\n",
    "    # prepare data\n",
    "    correction = 0.0\n",
    "    if n_diff > 0:\n",
    "        correction = history[-n_diff]\n",
    "    history = difference(history, n_diff)\n",
    "    x_input = array(history[-n_input:]).reshape((1, n_input, 1))\n",
    "    # forecast\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    return correction + yhat[0]\n",
    "\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # fit model\n",
    "    model = model_fit(train, cfg)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = model_predict(model, history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions) \n",
    "    print(' > %.3f' % error)\n",
    "    return error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=3):\n",
    "    # convert config to a key\n",
    "    key = str(config)\n",
    "    # fit and evaluate the model n times\n",
    "    scores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)] \n",
    "    # summarize score\n",
    "    result = mean(scores)\n",
    "    print('> Model[%s] %.3f' % (key, result))\n",
    "    return (key, result)\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test):\n",
    "    # evaluate configs\n",
    "    scores  = [repeat_evaluate(data, cfg, n_test) for cfg in cfg_list]\n",
    "    # sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores\n",
    "\n",
    "# create a list of configs to try\n",
    "def model_configs():\n",
    "    # define scope of configs\n",
    "    n_input = [12]\n",
    "    n_filters = [64]\n",
    "    n_kernels = [3, 5]\n",
    "    n_epochs = [100]\n",
    "    n_batch = [1, 150]\n",
    "    n_diff = [0, 12]\n",
    "    # create configs\n",
    "    configs = list()\n",
    "    for a in n_input:\n",
    "        for b in n_filters:\n",
    "            for c in n_kernels:\n",
    "                for d in n_epochs:\n",
    "                    for e in n_batch:\n",
    "                        for f in n_diff:\n",
    "                            cfg = [a,b,c,d,e,f]\n",
    "                            configs.append(cfg)\n",
    "    print('Total configs: %d' % len(configs)) \n",
    "    return configs\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # define dataset\n",
    "    series = read_csv('monthly-airline-passengers.csv', header=0, index_col=0) \n",
    "    data = series.values\n",
    "    # data split\n",
    "    n_test = 12\n",
    "    # model configs\n",
    "    cfg_list = model_configs()\n",
    "    # grid search\n",
    "    scores = grid_search(data, cfg_list, n_test) \n",
    "    print('done')\n",
    "    # list top 10 configs\n",
    "    for cfg, error in scores[:3]:\n",
    "        print(cfg, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccbee54",
   "metadata": {},
   "source": [
    "Running the example, we can see that only eight distinct configurations are evaluated. We can see that a configuration of [12, 64, 5, 100, 1, 12] achieved an RMSE of 18.89, which is skillful as compared to a naive forecast model that achieved 50.70. We can unpack this configuration as:\n",
    "- n input: 12\n",
    "- n filters: 64 \n",
    "- n kernel: 5\n",
    "- n epochs: 100 \n",
    "- n batch: 1\n",
    "- n diff: 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c72c5f",
   "metadata": {},
   "source": [
    "## 15.6 Long Short-Term Memory Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b742b12",
   "metadata": {},
   "source": [
    "We can now adopt the framework for grid searching the hyperparameters of an LSTM model. For more details on modeling a univariate time series with an LSTM network, see Chapter 9. The hyperparameters for the LSTM model will be the same five as the MLP; they are:\n",
    "- n input: The number of prior inputs to use as input for the model (e.g. 12 months). \n",
    "- n nodes: The number of nodes to use in the hidden layer (e.g. 50).\n",
    "- n epochs: The number of training epochs (e.g. 1000).\n",
    "- n batch: The number of samples to include in each minibatch (e.g. 32).\n",
    "- n diff: The difference order (e.g. 0 or 12)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f49ecc1",
   "metadata": {},
   "source": [
    "It may be interesting to explore tuning additional configurations such as the use of a **bidirectional** input layer, **stacked** LSTM layers, and even **hybrid models** with CNN or ConvLSTM input models. As with the CNN model, the LSTM model expects input data to have a **three- dimensional** shape for **[the samples, time steps, and features]**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8d5031",
   "metadata": {},
   "source": [
    "**The complete example is listed below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bdf792ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configs: 2\n",
      " > 28.115\n",
      " > 22.236\n",
      "> Model[[12, 100, 50, 1, 12]] 25.175\n",
      " > 23.502\n",
      " > 21.654\n",
      "> Model[[12, 100, 50, 150, 12]] 22.578\n",
      "done\n",
      "[12, 100, 50, 150, 12] 22.57805635247734\n",
      "[12, 100, 50, 1, 12] 25.17525287218828\n"
     ]
    }
   ],
   "source": [
    "# grid search lstm for monthly airline passengers dataset\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in, n_out=1):\n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg.values\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# difference dataset\n",
    "def difference(data, order):\n",
    "    return [data[i] - data[i - order] for i in range(order, len(data))]\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    # unpack config\n",
    "    n_input, n_nodes, n_epochs, n_batch, n_diff = config\n",
    "    # prepare data\n",
    "    if n_diff > 0:\n",
    "        train = difference(train, n_diff)\n",
    "    # transform series into supervised format\n",
    "    data = series_to_supervised(train, n_in=n_input)\n",
    "    # separate inputs and outputs\n",
    "    train_x, train_y = data[:, :-1], data[:, -1]\n",
    "    # reshape input data into [samples, timesteps, features]\n",
    "    n_features = 1\n",
    "    train_x = train_x.reshape((train_x.shape[0], train_x.shape[1], n_features))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_nodes, activation='relu', input_shape=(n_input, n_features))) \n",
    "    model.add(Dense(n_nodes, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit model\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0) \n",
    "    return model\n",
    "\n",
    "# forecast with the fit model\n",
    "def model_predict(model, history, config):\n",
    "    # unpack config\n",
    "    n_input, _, _, _, n_diff = config\n",
    "    # prepare data\n",
    "    correction = 0.0\n",
    "    if n_diff > 0:\n",
    "        correction = history[-n_diff]\n",
    "    history = difference(history, n_diff)\n",
    "    # shape input for model\n",
    "    x_input = array(history[-n_input:]).reshape((1, n_input))\n",
    "    # make forecast\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    # correct forecast if it was differenced\n",
    "    return correction + yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # fit model\n",
    "    model = model_fit(train, cfg)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = model_predict(model, history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions) \n",
    "    print(' > %.3f' % error)\n",
    "    return error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=2):\n",
    "    # convert config to a key\n",
    "    key = str(config)\n",
    "    # fit and evaluate the model n times\n",
    "    scores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)] # summarize score\n",
    "    result = mean(scores)\n",
    "    print('> Model[%s] %.3f' % (key, result))\n",
    "    return (key, result)\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test):\n",
    "    # evaluate configs\n",
    "    scores  = [repeat_evaluate(data, cfg, n_test) for cfg in cfg_list]\n",
    "    # sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores\n",
    "\n",
    "# create a list of configs to try\n",
    "def model_configs():\n",
    "    # define scope of configs\n",
    "    n_input = [12]\n",
    "    n_nodes = [100]\n",
    "    n_epochs = [50]\n",
    "    n_batch = [1, 150]\n",
    "    n_diff = [12]\n",
    "    # create configs\n",
    "    configs = list()\n",
    "    for i in n_input:\n",
    "        for j in n_nodes:\n",
    "            for k in n_epochs:\n",
    "                for l in n_batch:\n",
    "                    for m in n_diff:\n",
    "                        cfg = [i, j, k, l, m]\n",
    "                        configs.append(cfg)\n",
    "    print('Total configs: %d' % len(configs)) \n",
    "    return configs\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # define dataset\n",
    "    series = read_csv('monthly-airline-passengers.csv', header=0, index_col=0) \n",
    "    data = series.values\n",
    "    # data split\n",
    "    n_test = 12\n",
    "    # model configs\n",
    "    cfg_list = model_configs()\n",
    "    # grid search\n",
    "#     print(data,cfg_list,n_test)\n",
    "    scores = grid_search(data, cfg_list, n_test) \n",
    "    print('done')\n",
    "    # list top 3 configs\n",
    "    for cfg, error in scores[:3]:\n",
    "        print(cfg, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db30189",
   "metadata": {},
   "source": [
    "Running the example, we can see that only two distinct configurations are evaluated. We can see that a configuration of [12, 100, 50, 1, 12] achieved an RMSE of 21.24, which is skillful as compared to a naive forecast model that achieved 50.70. The model requires a lot more tuning and may do much better with a hybrid configuration, such as having a CNN model as input. We can unpack this configuration as:\n",
    "- n input: 12 \n",
    "- n nodes: 100 \n",
    "- n epochs: 50 \n",
    "- n batch: 1\n",
    "- n diff: 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd0353d",
   "metadata": {},
   "source": [
    "## 15.7 Extensions\n",
    "This section lists some ideas for extending the tutorial that you may wish to explore.\n",
    "- More Configurations. Explore a large suite of configurations for one of the models and see if you can find a configuration that results in better performance.\n",
    "- Data Scaling. Update the grid search framework to also support the scaling (normal- ization and/or standardization) of data both before fitting the model and inverting the transform for predictions.\n",
    "- Network Architecture. Explore the grid searching larger architectural changes for a given model, such as the addition of more hidden layers.\n",
    "- New Dataset. Explore the grid search of a given model in a new univariate time series dataset.\n",
    "- Multivariate. Update the grid search framework to support small multivariate time series datasets, e.g. datasets with multiple input variables.\n",
    "If you explore any of these extensions, I’d love to know.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525beaf4",
   "metadata": {},
   "source": [
    "## 15.9 Summary\n",
    "In this tutorial, you discovered how to develop a framework to grid search hyperparameters for deep learning models. Specifically, you learned:\n",
    "- How to develop a generic（普通的） grid searching framework for tuning model hyperparameters.\n",
    "- How to grid search hyperparameters for a Multilayer Perceptron model on the airline\n",
    "passengers univariate time series forecasting problem.\n",
    "- How to adapt the framework to grid search hyperparameters for convolutional and long short-term memory neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cfeaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
