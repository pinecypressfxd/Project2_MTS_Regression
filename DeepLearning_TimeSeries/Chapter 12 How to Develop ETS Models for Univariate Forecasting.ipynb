{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "322378cd",
   "metadata": {},
   "source": [
    "# Chapter 12 How to Develop ETS Models for Univariate Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c440df",
   "metadata": {},
   "source": [
    "In this tutorial, you will discover how to develop a framework for grid searching all of the exponential smoothing model hyperparameters for univariate time series forecasting. After completing this tutorial, you will know:\n",
    "- How to develop a framework for grid searching ETS models from scratch using walk-forward validation.\n",
    "- How to grid search ETS model hyperparameters for daily time series data for female births.\n",
    "- How to grid search ETS model hyperparameters for monthly time series data for shampoo sales, car sales, and temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc2caa7",
   "metadata": {},
   "source": [
    "## 12.1 Tutorial Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e202734",
   "metadata": {},
   "source": [
    "## 12.2 Develop a Grid Search Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9314f613",
   "metadata": {},
   "source": [
    "In this section, we will develop a framework for grid searching exponential smoothing model hyperparameters for a given univariate time series forecasting problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640f4860",
   "metadata": {},
   "source": [
    "We will use the implementation of **Holt-Winters Exponential Smoothing** provided by the Statsmodels library. This model has hyperparameters that control the nature of the exponential performed for the series, trend, and seasonality, specifically:\n",
    "- smoothing level (alpha): the smoothing coefficient for the level.\n",
    "- smoothing slope (beta): the smoothing coefficient for the trend.\n",
    "- smoothing seasonal (gamma): the smoothing coefficient for the seasonal component. \n",
    "- damping slope (phi): the coefficient for the damped trend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae3a9d",
   "metadata": {},
   "source": [
    "All four of these hyperparameters can be specified when defining the model. If they are not specified, the library will automatically tune the model and find the optimal values for these hyperparameters (e.g. optimized=True). There are other hyperparameters that the model will not automatically tune that you may want to specify; they are:\n",
    "- trend: The type of trend component, as either add for additive or mul for multiplicative. Modeling the trend can be disabled by setting it to None.\n",
    "- damped: Whether or not the trend component should be damped, either True or False.\n",
    "- seasonal: The type of seasonal component, as either add for additive or mul for multi-\n",
    "plicative. Modeling the seasonal component can be disabled by setting it to None.\n",
    "- seasonal periods: The number of time steps in a seasonal period, e.g. 12 for 12 months\n",
    "in a yearly seasonal structure.\n",
    "- use boxcox: Whether or not to perform a power transform of the series (True/False) or specify the lambda for the transform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50deee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-step Holt Winter's Exponential Smoothing forecast \n",
    "def exp_smoothing_forecast(history, config):\n",
    "    t,d,s,p,b,r = config\n",
    "    # define model\n",
    "    history = array(history)\n",
    "    model = ExponentialSmoothing(history, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n",
    "    # fit model\n",
    "    model_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n",
    "    # make one step forecast\n",
    "    yhat = model_fit.predict(len(history), len(history))\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4345b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search simple forecast for daily female births\n",
    "from math import sqrt\n",
    "from numpy import mean\n",
    "from numpy import median\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import read_csv\n",
    "from numpy import array\n",
    "\n",
    "\n",
    "# one-step Holt Winter's Exponential Smoothing forecast \n",
    "def exp_smoothing_forecast(history, config):\n",
    "    t,d,s,p,b,r = config\n",
    "    # define model\n",
    "    history = array(history)\n",
    "    model = ExponentialSmoothing(history, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n",
    "    # fit model\n",
    "    model_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n",
    "    # make one step forecast\n",
    "    yhat = model_fit.predict(len(history), len(history))\n",
    "    return yhat[0]\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "# split a univariate dataset into train/test sets\n",
    "\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = exp_smoothing_forecast(history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    return error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def score_model(data, n_test, cfg, debug=False):\n",
    "    result = None\n",
    "    # convert config to a key\n",
    "    key = str(cfg)\n",
    "    # show all warnings and fail on exception if debugging\n",
    "    if debug:\n",
    "        result = walk_forward_validation(data, n_test, cfg)\n",
    "    else:\n",
    "        # one failure during model validation suggests an unstable config\n",
    "        try:\n",
    "        # never show warnings when grid searching, too noisy\n",
    "            with catch_warnings():\n",
    "                filterwarnings(\"ignore\")\n",
    "                result = walk_forward_validation(data, n_test, cfg)\n",
    "        except:\n",
    "            error = None\n",
    "      # check for an interesting result\n",
    "    if result is not None:\n",
    "        print(' > Model[%s] %.3f' % (key, result))\n",
    "    return (key, result)\n",
    "\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "    scores = None\n",
    "    if parallel:\n",
    "    # execute configs in parallel\n",
    "        executor = Parallel(n_jobs=cpu_count(), backend='multiprocessing') \n",
    "        tasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list) \n",
    "        scores = executor(tasks)\n",
    "    else:\n",
    "        scores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "    # remove empty results\n",
    "    scores = [r for r in scores if r[1] != None]\n",
    "    # sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores\n",
    "\n",
    "# create a set of exponential smoothing configs to try\n",
    "def exp_smoothing_configs(seasonal=[None]): \n",
    "    models = list()\n",
    "    # define config lists\n",
    "    t_params = ['add', 'mul', None]\n",
    "    d_params = [True, False] \n",
    "    s_params = ['add', 'mul', None] \n",
    "    p_params = seasonal\n",
    "    b_params = [True, False] \n",
    "    r_params = [True, False]\n",
    "    # create config instances\n",
    "    for t in t_params:\n",
    "        for d in d_params:\n",
    "            for s in s_params:\n",
    "                for p in p_params:\n",
    "                    for b in b_params:\n",
    "                        for r in r_params:\n",
    "                            cfg = [t,d,s,p,b,r]\n",
    "                            models.append(cfg)\n",
    "    return models\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # define dataset\n",
    "    data = [10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0] \n",
    "    print(data)\n",
    "    # data split\n",
    "    n_test = 4\n",
    "    # model configs\n",
    "    cfg_list = exp_smoothing_configs()\n",
    "    # grid search\n",
    "    scores = grid_search(data, cfg_list, n_test)\n",
    "    print('done')\n",
    "    # list top 3 configs\n",
    "    for cfg, error in scores[:3]:\n",
    "        print(cfg, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c91c4ed",
   "metadata": {},
   "source": [
    "\n",
    "Now that we have a robust framework for grid searching ETS model hyperparameters, letâ€™s test it out on a suite of standard univariate time series datasets. The datasets were chosen for demonstration purposes; I am not suggesting that an ETS model is the best approach for each dataset, and perhaps an SARIMA or something else would be more appropriate in some cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a24d8d5",
   "metadata": {},
   "source": [
    "## 12.3 Case Study 1: No Trend or Seasonality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c31f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search simple forecast for daily female births\n",
    "from math import sqrt\n",
    "from numpy import mean\n",
    "from numpy import median\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import read_csv\n",
    "from numpy import array\n",
    "\n",
    "\n",
    "# one-step Holt Winter's Exponential Smoothing forecast \n",
    "def exp_smoothing_forecast(history, config):\n",
    "    t,d,s,p,b,r = config\n",
    "    # define model\n",
    "    history = array(history)\n",
    "    model = ExponentialSmoothing(history, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n",
    "    # fit model\n",
    "    model_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n",
    "    # make one step forecast\n",
    "    yhat = model_fit.predict(len(history), len(history))\n",
    "    return yhat[0]\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "# split a univariate dataset into train/test sets\n",
    "\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = exp_smoothing_forecast(history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    return error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def score_model(data, n_test, cfg, debug=False):\n",
    "    result = None\n",
    "    # convert config to a key\n",
    "    key = str(cfg)\n",
    "    # show all warnings and fail on exception if debugging\n",
    "    if debug:\n",
    "        result = walk_forward_validation(data, n_test, cfg)\n",
    "    else:\n",
    "        # one failure during model validation suggests an unstable config\n",
    "        try:\n",
    "        # never show warnings when grid searching, too noisy\n",
    "            with catch_warnings():\n",
    "                filterwarnings(\"ignore\")\n",
    "                result = walk_forward_validation(data, n_test, cfg)\n",
    "        except:\n",
    "            error = None\n",
    "      # check for an interesting result\n",
    "    if result is not None:\n",
    "        print(' > Model[%s] %.3f' % (key, result))\n",
    "    return (key, result)\n",
    "\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "    scores = None\n",
    "    if parallel:\n",
    "    # execute configs in parallel\n",
    "        executor = Parallel(n_jobs=cpu_count(), backend='multiprocessing') \n",
    "        tasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list) \n",
    "        scores = executor(tasks)\n",
    "    else:\n",
    "        scores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "    # remove empty results\n",
    "    scores = [r for r in scores if r[1] != None]\n",
    "    # sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores\n",
    "\n",
    "# create a set of exponential smoothing configs to try\n",
    "def exp_smoothing_configs(seasonal=[None]): \n",
    "    models = list()\n",
    "    # define config lists\n",
    "    t_params = ['add', 'mul', None]\n",
    "    d_params = [True, False] \n",
    "    s_params = ['add', 'mul', None] \n",
    "    p_params = seasonal\n",
    "    b_params = [True, False] \n",
    "    r_params = [True, False]\n",
    "    # create config instances\n",
    "    for t in t_params:\n",
    "        for d in d_params:\n",
    "            for s in s_params:\n",
    "                for p in p_params:\n",
    "                    for b in b_params:\n",
    "                        for r in r_params:\n",
    "                            cfg = [t,d,s,p,b,r]\n",
    "                            models.append(cfg)\n",
    "    return models\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # load dataset\n",
    "    series = read_csv('daily-total-female-births.csv', header=0, index_col=0) \n",
    "    data = series.values\n",
    "    # data split\n",
    "    n_test = 165\n",
    "    # model configs\n",
    "    cfg_list = exp_smoothing_configs()\n",
    "    # grid search\n",
    "    scores = grid_search(data[:,0], cfg_list, n_test)\n",
    "    print('done')\n",
    "    # list top 3 configs\n",
    "    for cfg, error in scores[:3]:\n",
    "        print(cfg, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19999aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  > Model[['add', True, None, None, False, False]] 7.239\n",
    "#  > Model[['add', True, None, None, False, True]] 7.248\n",
    "#  > Model[['add', False, None, None, False, True]] 7.163\n",
    "#  > Model[['add', False, None, None, False, False]] 7.153\n",
    "#  > Model[['add', False, None, None, True, True]] 7.162\n",
    "#  > Model[['add', False, None, None, True, False]] 7.170\n",
    "#  > Model[['add', True, None, None, True, False]] 7.364\n",
    "#  > Model[['add', True, None, None, True, True]] 7.321\n",
    "#  > Model[[None, False, None, None, False, True]] 7.121\n",
    "#  > Model[[None, False, None, None, False, False]] 7.130\n",
    "#  > Model[[None, False, None, None, True, False]] 7.175\n",
    "#  > Model[[None, False, None, None, True, True]] 7.123\n",
    "#  > Model[['mul', True, None, None, False, False]] 27.111\n",
    "#  > Model[['mul', True, None, None, False, True]] 8.097\n",
    "#  > Model[['mul', True, None, None, True, False]] 452.678\n",
    "#  > Model[['mul', True, None, None, True, True]] 20.492\n",
    "#  > Model[['mul', False, None, None, False, True]] 7.193\n",
    "#  > Model[['mul', False, None, None, False, False]] 7.184\n",
    "#  > Model[['mul', False, None, None, True, False]] 7.137\n",
    "#  > Model[['mul', False, None, None, True, True]] 7.132\n",
    "# done\n",
    "# [None, False, None, None, False, True] 7.120813209471283\n",
    "# [None, False, None, None, True, True] 7.123337549559455\n",
    "# [None, False, None, None, False, False] 7.1299539248543375"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14efb01c",
   "metadata": {},
   "source": [
    "## 12.4 Case Study 2: Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f809c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search simple forecast for daily female births\n",
    "from math import sqrt\n",
    "from numpy import mean\n",
    "from numpy import median\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import read_csv\n",
    "from numpy import array\n",
    "\n",
    "\n",
    "# one-step Holt Winter's Exponential Smoothing forecast \n",
    "def exp_smoothing_forecast(history, config):\n",
    "    t,d,s,p,b,r = config\n",
    "    # define model\n",
    "    history = array(history)\n",
    "    model = ExponentialSmoothing(history, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n",
    "    # fit model\n",
    "    model_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n",
    "    # make one step forecast\n",
    "    yhat = model_fit.predict(len(history), len(history))\n",
    "    return yhat[0]\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "# split a univariate dataset into train/test sets\n",
    "\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = exp_smoothing_forecast(history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    return error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def score_model(data, n_test, cfg, debug=False):\n",
    "    result = None\n",
    "    # convert config to a key\n",
    "    key = str(cfg)\n",
    "    # show all warnings and fail on exception if debugging\n",
    "    if debug:\n",
    "        result = walk_forward_validation(data, n_test, cfg)\n",
    "    else:\n",
    "        # one failure during model validation suggests an unstable config\n",
    "        try:\n",
    "        # never show warnings when grid searching, too noisy\n",
    "            with catch_warnings():\n",
    "                filterwarnings(\"ignore\")\n",
    "                result = walk_forward_validation(data, n_test, cfg)\n",
    "        except:\n",
    "            error = None\n",
    "      # check for an interesting result\n",
    "    if result is not None:\n",
    "        print(' > Model[%s] %.3f' % (key, result))\n",
    "    return (key, result)\n",
    "\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "    scores = None\n",
    "    if parallel:\n",
    "    # execute configs in parallel\n",
    "        executor = Parallel(n_jobs=cpu_count(), backend='multiprocessing') \n",
    "        tasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list) \n",
    "        scores = executor(tasks)\n",
    "    else:\n",
    "        scores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "    # remove empty results\n",
    "    scores = [r for r in scores if r[1] != None]\n",
    "    # sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores\n",
    "\n",
    "# create a set of exponential smoothing configs to try\n",
    "def exp_smoothing_configs(seasonal=[None]): \n",
    "    models = list()\n",
    "    # define config lists\n",
    "    t_params = ['add', 'mul', None]\n",
    "    d_params = [True, False] \n",
    "    s_params = ['add', 'mul', None] \n",
    "    p_params = seasonal\n",
    "    b_params = [True, False] \n",
    "    r_params = [True, False]\n",
    "    # create config instances\n",
    "    for t in t_params:\n",
    "        for d in d_params:\n",
    "            for s in s_params:\n",
    "                for p in p_params:\n",
    "                    for b in b_params:\n",
    "                        for r in r_params:\n",
    "                            cfg = [t,d,s,p,b,r]\n",
    "                            models.append(cfg)\n",
    "    return models\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # load dataset\n",
    "    series = read_csv('daily-total-female-births.csv', header=0, index_col=0) \n",
    "    data = series.values\n",
    "    # data split\n",
    "    n_test = 165\n",
    "    # model configs\n",
    "    cfg_list = exp_smoothing_configs()\n",
    "    # grid search\n",
    "    scores = grid_search(data[:,0], cfg_list, n_test)\n",
    "    print('done')\n",
    "    # list top 3 configs\n",
    "    for cfg, error in scores[:3]:\n",
    "        print(cfg, error)\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    # load dataset\n",
    "    series = read_csv('monthly-shampoo-sales.csv', header=0, index_col=0) \n",
    "    data = series.values\n",
    "    # data split\n",
    "    n_test = 12\n",
    "    # model configs\n",
    "    cfg_list = exp_smoothing_configs()\n",
    "    # grid search\n",
    "    scores = grid_search(data[:,0], cfg_list, n_test) \n",
    "    print('done')\n",
    "    # list top 3 configs\n",
    "    for cfg, error in scores[:3]:\n",
    "        print(cfg, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae77fd5",
   "metadata": {},
   "source": [
    "## 12.5 Case Study 3: Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8191c640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search simple forecast for daily female births\n",
    "from math import sqrt\n",
    "from numpy import mean\n",
    "from numpy import median\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import read_csv\n",
    "from numpy import array\n",
    "\n",
    "\n",
    "# one-step Holt Winter's Exponential Smoothing forecast \n",
    "def exp_smoothing_forecast(history, config):\n",
    "    t,d,s,p,b,r = config\n",
    "    # define model\n",
    "    history = array(history)\n",
    "    model = ExponentialSmoothing(history, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n",
    "    # fit model\n",
    "    model_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n",
    "    # make one step forecast\n",
    "    yhat = model_fit.predict(len(history), len(history))\n",
    "    return yhat[0]\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "# split a univariate dataset into train/test sets\n",
    "\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = exp_smoothing_forecast(history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    return error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def score_model(data, n_test, cfg, debug=False):\n",
    "    result = None\n",
    "    # convert config to a key\n",
    "    key = str(cfg)\n",
    "    # show all warnings and fail on exception if debugging\n",
    "    if debug:\n",
    "        result = walk_forward_validation(data, n_test, cfg)\n",
    "    else:\n",
    "        # one failure during model validation suggests an unstable config\n",
    "        try:\n",
    "        # never show warnings when grid searching, too noisy\n",
    "            with catch_warnings():\n",
    "                filterwarnings(\"ignore\")\n",
    "                result = walk_forward_validation(data, n_test, cfg)\n",
    "        except:\n",
    "            error = None\n",
    "      # check for an interesting result\n",
    "    if result is not None:\n",
    "        print(' > Model[%s] %.3f' % (key, result))\n",
    "    return (key, result)\n",
    "\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "    scores = None\n",
    "    if parallel:\n",
    "    # execute configs in parallel\n",
    "        executor = Parallel(n_jobs=cpu_count(), backend='multiprocessing') \n",
    "        tasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list) \n",
    "        scores = executor(tasks)\n",
    "    else:\n",
    "        scores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "    # remove empty results\n",
    "    scores = [r for r in scores if r[1] != None]\n",
    "    # sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores\n",
    "\n",
    "# create a set of exponential smoothing configs to try\n",
    "def exp_smoothing_configs(seasonal=[None]): \n",
    "    models = list()\n",
    "    # define config lists\n",
    "    t_params = ['add', 'mul', None]\n",
    "    d_params = [True, False] \n",
    "    s_params = ['add', 'mul', None] \n",
    "    p_params = seasonal\n",
    "    b_params = [True, False] \n",
    "    r_params = [True, False]\n",
    "    # create config instances\n",
    "    for t in t_params:\n",
    "        for d in d_params:\n",
    "            for s in s_params:\n",
    "                for p in p_params:\n",
    "                    for b in b_params:\n",
    "                        for r in r_params:\n",
    "                            cfg = [t,d,s,p,b,r]\n",
    "                            models.append(cfg)\n",
    "    return models \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    # load dataset\n",
    "    series = read_csv('monthly-mean-temp.csv', header=0, index_col=0) \n",
    "    data = series.values\n",
    "    # trim dataset to 5 years\n",
    "    data = data[-(5*12):]\n",
    "    # data split\n",
    "    n_test = 12\n",
    "    # model configs\n",
    "    cfg_list = exp_smoothing_configs(seasonal=[0,12])\n",
    "    # grid search\n",
    "    scores = grid_search(data[:,0], cfg_list, n_test)\n",
    "    print('done')\n",
    "    # list top 3 configs\n",
    "    for cfg, error in scores[:3]:\n",
    "        print(cfg, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c1d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# > Model[['mul', False, 'add', 12, True, True]] 1.642\n",
    "#  > Model[['mul', False, 'add', 12, True, False]] 1.632\n",
    "#  > Model[['mul', False, 'add', 12, False, True]] 1.580\n",
    "#  > Model[[None, False, None, 0, True, True]] 5.188\n",
    "#  > Model[['mul', False, 'add', 12, False, False]] 1.580\n",
    "#  > Model[[None, False, None, 0, False, True]] 5.187\n",
    "#  > Model[[None, False, None, 0, False, False]] 5.143\n",
    "#  > Model[[None, False, None, 0, True, False]] 5.143\n",
    "#  > Model[[None, False, None, 12, True, True]] 5.188\n",
    "#  > Model[[None, False, 'mul', 12, True, True]] 1.507\n",
    "#  > Model[[None, False, None, 12, False, True]] 5.187\n",
    "#  > Model[[None, False, None, 12, False, False]] 5.143\n",
    "#  > Model[[None, False, 'mul', 12, True, False]] 1.506\n",
    "#  > Model[[None, False, None, 12, True, False]] 5.143\n",
    "#  > Model[[None, False, 'mul', 12, False, True]] 1.502\n",
    "#  > Model[[None, False, 'mul', 12, False, False]] 1.502\n",
    "#  > Model[['mul', False, 'mul', 12, True, True]] 1.630\n",
    "#  > Model[['mul', False, 'mul', 12, True, False]] 1.620\n",
    "#  > Model[['mul', False, 'mul', 12, False, True]] 1.548\n",
    "#  > Model[['mul', False, 'mul', 12, False, False]] 1.548\n",
    "# done\n",
    "# [None, False, 'add', 12, False, False] 1.5015521597703008\n",
    "# [None, False, 'add', 12, False, True] 1.5015554955632213\n",
    "# [None, False, 'mul', 12, False, True] 1.501559274317846"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eada45",
   "metadata": {},
   "source": [
    "## 12.6 Case Study 4: Trend and Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b53608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search simple forecast for daily female births\n",
    "from math import sqrt\n",
    "from numpy import mean\n",
    "from numpy import median\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import read_csv\n",
    "from numpy import array\n",
    "\n",
    "\n",
    "# one-step Holt Winter's Exponential Smoothing forecast \n",
    "def exp_smoothing_forecast(history, config):\n",
    "    t,d,s,p,b,r = config\n",
    "    # define model\n",
    "    history = array(history)\n",
    "    model = ExponentialSmoothing(history, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n",
    "    # fit model\n",
    "    model_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n",
    "    # make one step forecast\n",
    "    yhat = model_fit.predict(len(history), len(history))\n",
    "    return yhat[0]\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "# split a univariate dataset into train/test sets\n",
    "\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = exp_smoothing_forecast(history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    return error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def score_model(data, n_test, cfg, debug=False):\n",
    "    result = None\n",
    "    # convert config to a key\n",
    "    key = str(cfg)\n",
    "    # show all warnings and fail on exception if debugging\n",
    "    if debug:\n",
    "        result = walk_forward_validation(data, n_test, cfg)\n",
    "    else:\n",
    "        # one failure during model validation suggests an unstable config\n",
    "        try:\n",
    "        # never show warnings when grid searching, too noisy\n",
    "            with catch_warnings():\n",
    "                filterwarnings(\"ignore\")\n",
    "                result = walk_forward_validation(data, n_test, cfg)\n",
    "        except:\n",
    "            error = None\n",
    "      # check for an interesting result\n",
    "    if result is not None:\n",
    "        print(' > Model[%s] %.3f' % (key, result))\n",
    "    return (key, result)\n",
    "\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "    scores = None\n",
    "    if parallel:\n",
    "    # execute configs in parallel\n",
    "        executor = Parallel(n_jobs=cpu_count(), backend='multiprocessing') \n",
    "        tasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list) \n",
    "        scores = executor(tasks)\n",
    "    else:\n",
    "        scores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "    # remove empty results\n",
    "    scores = [r for r in scores if r[1] != None]\n",
    "    # sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores\n",
    "\n",
    "# create a set of exponential smoothing configs to try\n",
    "def exp_smoothing_configs(seasonal=[None]): \n",
    "    models = list()\n",
    "    # define config lists\n",
    "    t_params = ['add', 'mul', None]\n",
    "    d_params = [True, False] \n",
    "    s_params = ['add', 'mul', None] \n",
    "    p_params = seasonal\n",
    "    b_params = [True, False] \n",
    "    r_params = [True, False]\n",
    "    # create config instances\n",
    "    for t in t_params:\n",
    "        for d in d_params:\n",
    "            for s in s_params:\n",
    "                for p in p_params:\n",
    "                    for b in b_params:\n",
    "                        for r in r_params:\n",
    "                            cfg = [t,d,s,p,b,r]\n",
    "                            models.append(cfg)\n",
    "    return models\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # load dataset\n",
    "    series = read_csv('monthly-car-sales.csv', header=0, index_col=0) \n",
    "    data = series.values\n",
    "    # data split\n",
    "    n_test = 12\n",
    "    # model configs\n",
    "    cfg_list = exp_smoothing_configs(seasonal=[0,6,12])\n",
    "    # grid search\n",
    "    scores = grid_search(data[:,0], cfg_list, n_test)\n",
    "    print('done')\n",
    "    # list top 3 configs\n",
    "    for cfg, error in scores[:3]:\n",
    "        print(cfg, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8d2920",
   "metadata": {},
   "source": [
    "## 12.9 Summary\n",
    "In this tutorial, you discovered how to develop a framework for grid searching all of the exponential smoothing model hyperparameters for univariate time series forecasting. Specifically, you learned:\n",
    "- How to develop a framework for grid searching ETS models from scratch using walk-forward validation.\n",
    "- How to grid search ETS model hyperparameters for daily time series data for births.\n",
    "- How to grid search ETS model hyperparameters for monthly time series data for shampoo\n",
    "sales, car sales and temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42de28a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
